{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj1B_M7jpL3B",
        "outputId": "e99e6052-6630-47ef-fb9a-30ef1828b888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9iy55dukZWa",
        "outputId": "76bade44-4c6f-4bf4-b1d0-cad3cd4fd628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "!pip install konlpy\n",
        "from konlpy.tag import Okt\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import warnings\n",
        "# WARNING 무시\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ods0aWJdp4q7"
      },
      "outputs": [],
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fBqZ3mznpf4n"
      },
      "outputs": [],
      "source": [
        "def clean_sentence(sentence):\n",
        "    sentence = re.sub(r'[^0-9ㄱ-ㅎㅏ-ㅣ가-힣 ]',r'', sentence)\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OF5G33_Ophby"
      },
      "outputs": [],
      "source": [
        "okt = Okt()\n",
        "def process_morph(sentence):\n",
        "    return ' '.join(okt.morphs(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UtW5jdMEyO_Q"
      },
      "outputs": [],
      "source": [
        "def clean_and_morph(sentence, is_question=True):\n",
        "    # 한글 문장 전처리\n",
        "    sentence = clean_sentence(sentence)\n",
        "    # 형태소 변환\n",
        "    sentence = process_morph(sentence)\n",
        "    # Question 인 경우, Answer인 경우를 분기하여 처리\n",
        "    if is_question:\n",
        "        return sentence\n",
        "    else:\n",
        "        # <SOS> 토큰은 decoder input에 <EOS> 토큰은 decoder output에 추가\n",
        "        return ('<SOS> ' + sentence, sentence + ' <EOS>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZI4z0P5EyPG5"
      },
      "outputs": [],
      "source": [
        "def make_prediction(model, question_inputs):\n",
        "    results = model(inputs=question_inputs, training=False)\n",
        "    # 변환된 인덱스를 문장으로 변환\n",
        "    results = np.asarray(results).reshape(-1)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OjNjMofWNLBC"
      },
      "outputs": [],
      "source": [
        "def make_question(sentence):\n",
        "    # 코드를 입력하세요\n",
        "    sentence = clean_and_morph(sentence)\n",
        "    question_sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "    return question_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xhTLUF54zpVK"
      },
      "outputs": [],
      "source": [
        "def run_chatbot(question):\n",
        "    input_seq = make_question(question)\n",
        "    states = encoder_model2.predict(input_seq)\n",
        "    # 목표 시퀀스 초기화\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    \n",
        "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
        "    target_seq[0, 0] = 2\n",
        "    # 인덱스 초기화\n",
        "    indexs = []\n",
        "    \n",
        "    # 디코더 타임 스텝 반복\n",
        "    while 1:\n",
        "        # 디코더로 현재 타임 스텝 출력 구함\n",
        "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
        "        decoder_outputs, state_h, state_c = decoder_model2.predict(\n",
        "                                                [target_seq] + states)\n",
        "    # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "        index = np.argmax(decoder_outputs[0, 0, :])\n",
        "        indexs.append(index)\n",
        "\n",
        "    # 종료 검사\n",
        "        if index == 3 or len(indexs) >= MAX_LENGTH:\n",
        "            break\n",
        "\n",
        "\n",
        "    # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = index\n",
        "\n",
        "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
        "        states = [state_h, state_c]\n",
        "    \n",
        "    \n",
        "    results = convert_index_to_text(indexs, tokenizer.word_index['<EOS>'])\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZREaS3BgTomk"
      },
      "outputs": [],
      "source": [
        "# loading\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/ssac/nlp/tokenizer/seq2seq_tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIlpU7gNTomk",
        "outputId": "650a5c09-4c92-4f1b-d5cf-1370b0563288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "# 모델 파일 로드\n",
        "encoder_model2 = models.load_model('/content/drive/MyDrive/Colab Notebooks/ssac/nlp/model/encoder_model.h5')\n",
        "decoder_model2 = models.load_model('/content/drive/MyDrive/Colab Notebooks/ssac/nlp/model/decoder_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1u0BhVfZUBcr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Li85yjnpUBft"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 100      # 임베딩 벡터 차원\n",
        "LSTM_HIDDEN_DIM = 128    # LSTM 히든레이어 차원\n",
        "MAX_LENGTH = 30\n",
        "TRUNCATING = 'post'      #문장이 30을 넘어갈 경우 뒤에서 자르기\n",
        "PADDING = 'post'         #뒤에서부터 0으로 패딩\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1  # 나중에 <PAD> 위해 +1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jl7g9teQsSVH"
      },
      "outputs": [],
      "source": [
        "def convert_index_to_text(indexs, end_token): \n",
        "    \n",
        "    sentence = ''\n",
        "  \n",
        "    for index in indexs:\n",
        "        if index == end_token:\n",
        "            break;\n",
        "        # 사전에 존재하는 단어의 경우 단어 추가\n",
        "        if index > 0 and tokenizer.index_word[index] is not None:\n",
        "            sentence += tokenizer.index_word[index]\n",
        "        else:\n",
        "        # 사전에 없는 인덱스면 빈 문자열 추가\n",
        "            sentence += ''\n",
        "       \n",
        "        sentence += ' '\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gCt-4PmTUgDz",
        "outputId": "c419c13e-273c-446d-b9a2-f44648e76199"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'한 십오분 쯤 걸려요 '"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_chatbot('얼마나 걸리나요?')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "seq2seq_predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
